# -*- coding: utf-8 -*-
"""SDA Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gRXRATfyPx11WLJ6VXzvHy2-ONIRCEs8

Import Functions
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler

"""Datasets loading"""

train_data=pd.read_csv('train data.csv')
train_data.head()

oil_prices=pd.read_csv('oil price.csv')
oil_prices.head()

holidays=pd.read_csv('holidays.csv')
print(holidays.head())

"""Converting date to datetime"""

train_data['date'] = pd.to_datetime(train_data['date'])
oil_prices['date'] = pd.to_datetime(oil_prices['date'])
holidays['date'] = pd.to_datetime(holidays['date'])
train_data.set_index('date', inplace=True)
oil_prices.set_index('date', inplace=True)
holidays.set_index('date', inplace=True)

"""Aggregating Sales"""

total_daily_sales = train_data.groupby('date')['sales'].sum()
total_daily_sales = total_daily_sales[total_daily_sales.index.drop_duplicates(keep='first')]
print("Dropped duplicate dates in sales data, if any.")
print(total_daily_sales)

holidays['holiday']=holidays['type'].apply(lambda x:1 if x=='Holiday' else 0)

"""Merging oil prices and holidays"""

exog_data = pd.merge(total_daily_sales, oil_prices[['dcoilwtico']], left_index=True, right_index=True, how='left')
exog_data = pd.merge(exog_data, holidays[['holiday']], left_index=True, right_index=True, how='left')

"""Checking Duplicates and removing them"""

total_daily_sales = total_daily_sales[total_daily_sales.index.drop_duplicates(keep='first')]
print("Dropped duplicate dates in sales data, if any.")
exog_data=exog_data.loc[exog_data.index.drop_duplicates(keep='first')]
print("Dropped Duplicates in exog data if any")
print(exog_data)

"""Checking Missing values and removing them"""

exog_data['dcoilwtico'] = exog_data['dcoilwtico'].ffill().bfill()  # Forward-fill and backward-fill missing oil prices
exog_data['holiday'] = exog_data['holiday'].fillna(0)  # Fill missing holiday values with 0 (non-holiday)

# Align exog_vars
exog_vars = exog_data[['dcoilwtico', 'holiday']]
exog_vars = exog_vars.loc[~exog_vars.index.duplicated(keep='first')]
exog_vars = exog_vars.reindex(total_daily_sales.index)

"""Scaling data"""

#Intialize scalers
scaler_sales=MinMaxScaler()
scaler_exog=MinMaxScaler()

total_daily_sales_scaled = scaler_sales.fit_transform(total_daily_sales.values.reshape(-1, 1))
exog_vars_scaled = scaler_exog.fit_transform(exog_vars)

"""Metrics"""

#Directinality accuracy
def directionality_accuracy(actual, predicted):
    actual = actual.flatten()
    return np.mean(np.sign(np.diff(actual)) == np.sign(np.diff(predicted)))

#RMSE
def evaluate_rmse_with_scaled_exog(total_daily_sales_scaled, exog_vars_scaled):
    # Create ARIMA model with scaled data
    exog_vars_scaled = exog_vars_scaled[:len(total_daily_sales_scaled)]
    model = ARIMA(total_daily_sales_scaled, order=(5, 1, 5), exog=exog_vars_scaled)
    model_fit = model.fit()
     # Forecast
    forecast_steps = 183
    train_end = len(total_daily_sales_scaled) - forecast_steps
    test = total_daily_sales_scaled[train_end:]
    predictions = model_fit.predict(start=train_end, end=len(total_daily_sales_scaled)-1, exog=exog_vars_scaled[train_end:])

    # RMSE
    rmse = np.sqrt(mean_squared_error(test, predictions))
    print(f"ARIMA(5,1,5) with Scaled Exogenous Variables - RMSE: {rmse}")

    # Directional Accuracy
    direction_acc = directionality_accuracy(test, predictions)
    print(f"ARIMA(5,1,5) Directionality Accuracy: {direction_acc * 100:.2f}%")

    return rmse, direction_acc, test, predictions, model_fit

# Evaluation
rmse, direction_acc, test, predictions, model_fit = evaluate_rmse_with_scaled_exog(total_daily_sales_scaled, exog_vars_scaled)

"""Forecasting"""

forecast_steps = 150
future_exog_vars = exog_vars_scaled[-forecast_steps:]  # Use the last known exogenous variables for forecasting
forecast = model_fit.forecast(steps=forecast_steps, exog=future_exog_vars)
forecast_index = pd.date_range(start=len(total_daily_sales_scaled), periods=forecast_steps, freq='D')
test_index = pd.date_range(start=len(total_daily_sales_scaled) - len(test), periods=len(test), freq='D')

"""Plotting"""

#plotting actual sales
plt.figure(figsize=(10, 6))
plt.plot(range(len(test)), test, label='Actual Sales', color='blue')
plt.plot(range(len(predictions)), predictions, label='Predicted Sales)', color='green')
plt.title('Actual vs Predicted Sales')
plt.xlabel('Days')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.show()

# plotting forecast sales
plt.figure(figsize=(10, 6))
plt.plot( forecast, label='Forecasted Sales)', color='red')
plt.title('Forecasted Sales')
plt.xlabel('Days')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.show()

print(forecast)

"""Output"""

output_data = pd.DataFrame({
    'Date': test_index.append(forecast_index),  # Append the test and forecast date ranges
    'Actual Sales': list(test) + [None] * forecast_steps,  # Actual sales for the test period
    'Predicted Sales': list(predictions) + [None] * forecast_steps,  # Predicted sales for the test period
    'Forecasted Sales': [None] * len(test) + list(forecast)  # Forecasted sales for the future period
})

output_data.to_csv('sales_predictions.csv', index=False)
print("CSV file saved as 'sales_predictions.csv'")

#For colab
#from google.colab import files
#files.download('sales_predictions.csv')

""".h5 File"""

#import joblib
#from google.colab import files
#output_data.to_hdf('sales_predictions.h5',key='df',mode='w')
#files.download('sales_predictions.h5')

#joblib.dump(model_fit, 'arima_model.pkl')
#files.download('arima_model.pkl')

